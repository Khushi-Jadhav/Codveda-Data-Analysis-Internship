# -*- coding: utf-8 -*-
"""ChurnPredictionCode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GgxaSKXsedUoLyi29mIdfLlGQH7N5uBJ
"""

# Step 1: Import Libraries
import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Step 2: Load Datasets
train_df = pd.read_csv("/content/drive/MyDrive/Data Set For Task/Churn Prdiction Data/churn-bigml-80.csv")
test_df = pd.read_csv("/content/drive/MyDrive/Data Set For Task/Churn Prdiction Data/churn-bigml-20.csv")

# Step 3: Basic Exploration
print(train_df.head())
print(train_df.info())
print(train_df['Churn'].value_counts())  # Target column

# Step 4: Preprocessing

# Drop only the existing irrelevant columns
cols_to_drop = ['State', 'Area code']  # Removed 'Phone'
train_df = train_df.drop(columns=cols_to_drop)
test_df = test_df.drop(columns=cols_to_drop)

# Label Encoding for categorical columns
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

label_cols = ['International plan', 'Voice mail plan']
for col in label_cols:
    train_df[col] = le.fit_transform(train_df[col])
    test_df[col] = le.transform(test_df[col])

# Encode the target column 'Churn'
train_df['Churn'] = le.fit_transform(train_df['Churn'])
test_df['Churn'] = le.transform(test_df['Churn'])

# Step 5: Split Features and Labels
X_train = train_df.drop('Churn', axis=1)
y_train = train_df['Churn']
X_test = test_df.drop('Churn', axis=1)
y_test = test_df['Churn']

# Step 6: Feature Scaling (optional but improves performance)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 7: Logistic Regression Model
lr = LogisticRegression()
lr.fit(X_train_scaled, y_train)
y_pred_lr = lr.predict(X_test_scaled)

print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr))

# Step 8: Random Forest Model
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)  # No scaling needed
y_pred_rf = rf.predict(X_test)

print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

# Step 9: Confusion Matrix for Random Forest
plt.figure(figsize=(6,4))
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Random Forest')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()



